{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicos word Capitulo 5\n",
    "- A Realizar todos los ejercicios propuestos de libro (excepto los de hive en caso de utilizar spark instalado en local y en el caso de RDBMS hacer únicamente ejemplo especificado más adelante)\n",
    "- B Pros y Cons utilizar UDFs\n",
    "- C Instalar MySQL, descargar driver y cargar datos de BBDD de empleados https://dev.mysql.com/doc/employee/en/ \n",
    "  - C.1 Cargar con spark datos de empleados y departamentos\n",
    "  - C.2 Mediante Joins mostrar toda la información de los empleados además de su título y salario.\n",
    "  - C.3 Diferencia entre Rank y dense_rank (operaciones de ventana) \n",
    "  \n",
    "  ##### Siempre debemos iniciar una instancia SparkSession al principio. \n",
    "\n",
    "Por lo que antes de comenzar crearemos la SparkSession correspondiente:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Creamos SparkSession\n",
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName('Ejs_Word_cap5') \\\n",
    "        .master('local[*]') \\\n",
    "        .config(\"spark.driver.extraClassPath\", \"C:/spark/jars/mysql-connector-java-8.0.23.jar\") \\\n",
    "        .getOrCreate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Pros y Cons utilizar UDFs\n",
    "\n",
    "Las UDFs son funciones creadas o definidas por el propio usuario, sirviendo de sistema para definir metodos SQL para operar sobre las columnas de un DF o Tabla. Se usan para definir una nueva columna basada en una función que extiende el vocabilario de SparkSQL para transformas DFo DS. Las UDFs se operan por sesión y no se guardan en el metastore.\n",
    "\n",
    "En cuanto a los Pros:\n",
    "- Se pueden utilizar por otros usuarios\n",
    "- No es necesario entender 100% su funcionamiento interno para su uso\n",
    "- Operan por cada SparkSession y no se guardan en el metastore \n",
    "\n",
    "En cuanto a los contras:\n",
    "- Su rendimiento es inferior en Python (Esto se resuelve usando Pandas/Vectorized UDFs) que en Scala o Java.\n",
    "- Spark SQL no puede optimizarlas\n",
    "- No garantiza el orden de evaluación de las subexpresiones/querys."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C Instalar MySQL, descargar driver y cargar datos de BBDD de empleados \n",
    "\n",
    "Para importar la bbdd hay que descargarla de https://github.com/Lism2992/MySQL-Employee-Database-Fix y seguidamente, desde la consola de mysql, lanzar el siguiente comando:\n",
    "\n",
    "SOURCE PATH/employees.sql\n",
    "\n",
    "Siendo PATH la ruta donde tienes descargado el archivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar un DF desde una fuente MySQL con el conector JBDC EJEMPLO NO LANZAR\n",
    "jdbcDF = ( spark.read\n",
    "                .format(\"jdbc\")\n",
    "                .option(\"url\", \"jdbc:mysql://[DBSERVER]:3306/[DATABASE]\")\n",
    "                .option(\"driver\", \"com.mysql.jdbc.Driver\")\n",
    "                .option(\"dbtable\", \"[TABLENAME]\")\n",
    "                .option(\"root\", \"[USERNAME]\")\n",
    "                .option(\"password\", \"[PASSWORD]\")\n",
    "                .load() )\n",
    "127.0.0.1 3306"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar DF a una bbdd MySQL con conector JDBC \n",
    "( jdbcDF.write\n",
    "        .format(\"jdbc\")\n",
    "        .option(\"url\", \"jdbc:mysql://[DBSERVER]:3306/[DATABASE]\")\n",
    "        .option(\"driver\", \"com.mysql.jdbc.Driver\")\n",
    "        .option(\"dbtable\", \"[TABLENAME]\")\n",
    "        .option(\"user\", \"[USERNAME]\")\n",
    "        .option(\"password\", \"[PASSWORD]\")\n",
    "        .save() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C.1 Cargar con spark datos de empleados y departamentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|dept_no|         dept_name|\n",
      "+-------+------------------+\n",
      "|   d009|  Customer Service|\n",
      "|   d005|       Development|\n",
      "|   d002|           Finance|\n",
      "|   d003|   Human Resources|\n",
      "|   d001|         Marketing|\n",
      "|   d004|        Production|\n",
      "|   d006|Quality Management|\n",
      "|   d008|          Research|\n",
      "|   d007|             Sales|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cargamos DF tabla departments\n",
    "departmentsDF = ( spark.read\n",
    "      .format(\"jdbc\")\n",
    "      .option(\"url\",\"jdbc:mysql://localhost/employees\")\n",
    "      .option(\"driver\",\"com.mysql.jdbc.Driver\")\n",
    "      .option(\"dbtable\",\"departments\")\n",
    "      .option(\"user\",\"root\")\n",
    "      .option(\"password\",\"root\")\n",
    "      .load() )\n",
    "departmentsDF.show()\n",
    "\n",
    "# Creamos vista temp\n",
    "departmentsDF.createOrReplaceTempView(\"employees\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows = 300024\n",
      "+------+----------+----------+---------+------+----------+\n",
      "|emp_no|birth_date|first_name|last_name|gender| hire_date|\n",
      "+------+----------+----------+---------+------+----------+\n",
      "| 10001|1953-09-02|    Georgi|  Facello|     M|1986-06-26|\n",
      "| 10002|1964-06-02|   Bezalel|   Simmel|     F|1985-11-21|\n",
      "| 10003|1959-12-03|     Parto|  Bamford|     M|1986-08-28|\n",
      "| 10004|1954-05-01| Chirstian|  Koblick|     M|1986-12-01|\n",
      "| 10005|1955-01-21|   Kyoichi| Maliniak|     M|1989-09-12|\n",
      "+------+----------+----------+---------+------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cargamos DF tabla employees\n",
    "employeesDF = ( spark.read\n",
    "      .format(\"jdbc\")\n",
    "      .option(\"url\",\"jdbc:mysql://localhost/employees\")\n",
    "      .option(\"driver\",\"com.mysql.jdbc.Driver\")\n",
    "      .option(\"dbtable\",\"employees\")\n",
    "      .option(\"user\",\"root\")\n",
    "      .option(\"password\",\"root\")\n",
    "      .load() )\n",
    "\n",
    "# Mostramos con un print el numero de lineas\n",
    "print(\"Total Rows = %d\" % (employeesDF.count()))\n",
    "employeesDF.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows = 2844047\n",
      "+------+------+----------+----------+\n",
      "|emp_no|salary| from_date|   to_date|\n",
      "+------+------+----------+----------+\n",
      "| 10001| 60117|1986-06-26|1987-06-26|\n",
      "| 10001| 62102|1987-06-26|1988-06-25|\n",
      "| 10001| 66074|1988-06-25|1989-06-25|\n",
      "| 10001| 66596|1989-06-25|1990-06-25|\n",
      "| 10001| 66961|1990-06-25|1991-06-25|\n",
      "+------+------+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cargamos DF tabla salaries\n",
    "salariesDF = ( spark.read\n",
    "      .format(\"jdbc\")\n",
    "      .option(\"url\",\"jdbc:mysql://localhost/employees\")\n",
    "      .option(\"driver\",\"com.mysql.jdbc.Driver\")\n",
    "      .option(\"dbtable\",\"salaries\")\n",
    "      .option(\"user\",\"root\")\n",
    "      .option(\"password\",\"root\")\n",
    "      .load() )\n",
    "\n",
    "# Mostramos con un print el numero de lineas\n",
    "print(\"Total Rows = %d\" % (salariesDF.count()))\n",
    "salariesDF.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows = 443308\n",
      "+------+---------------+----------+----------+\n",
      "|emp_no|          title| from_date|   to_date|\n",
      "+------+---------------+----------+----------+\n",
      "| 10001|Senior Engineer|1986-06-26|9999-01-01|\n",
      "| 10002|          Staff|1996-08-03|9999-01-01|\n",
      "| 10003|Senior Engineer|1995-12-03|9999-01-01|\n",
      "| 10004|       Engineer|1986-12-01|1995-12-01|\n",
      "| 10004|Senior Engineer|1995-12-01|9999-01-01|\n",
      "| 10005|   Senior Staff|1996-09-12|9999-01-01|\n",
      "| 10005|          Staff|1989-09-12|1996-09-12|\n",
      "| 10006|Senior Engineer|1990-08-05|9999-01-01|\n",
      "| 10007|   Senior Staff|1996-02-11|9999-01-01|\n",
      "| 10007|          Staff|1989-02-10|1996-02-11|\n",
      "+------+---------------+----------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cargamos DF tabla titles\n",
    "titlesDF = ( spark.read\n",
    "      .format(\"jdbc\")\n",
    "      .option(\"url\",\"jdbc:mysql://localhost/employees\")\n",
    "      .option(\"driver\",\"com.mysql.jdbc.Driver\")\n",
    "      .option(\"dbtable\",\"titles\")\n",
    "      .option(\"user\",\"root\")\n",
    "      .option(\"password\",\"root\")\n",
    "      .load() )\n",
    "\n",
    "# Mostramos con un print el numero de lineas\n",
    "print(\"Total Rows = %d\" % (titlesDF.count()))\n",
    "titlesDF.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos las respectivas vistas temporales para poder usar SQLpuro\n",
    "employeesDF.createOrReplaceTempView(\"employees\")\n",
    "salariesDF.createOrReplaceTempView(\"salaries\")\n",
    "titlesDF.createOrReplaceTempView(\"titles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C.2 Mediante Joins mostrar toda la información de los empleados además de su título y salario.\n",
    "\n",
    "tabla employees entera + tabla salaries (salary) + tabla titles (titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+----------------+------+------+----------------+\n",
      "|emp_no|birth_date|            Name|gender|salary|           title|\n",
      "+------+----------+----------------+------+------+----------------+\n",
      "| 10206|1960-09-19|Alassane Iwayama|     F| 40000|Technique Leader|\n",
      "| 10206|1960-09-19|Alassane Iwayama|     F| 43519|Technique Leader|\n",
      "| 10206|1960-09-19|Alassane Iwayama|     F| 46265|Technique Leader|\n",
      "| 10206|1960-09-19|Alassane Iwayama|     F| 46865|Technique Leader|\n",
      "| 10206|1960-09-19|Alassane Iwayama|     F| 47837|Technique Leader|\n",
      "+------+----------+----------------+------+------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lenguaje SQLpuro\n",
    "spark.sql( \"\"\"SELECT A.emp_no, \n",
    "                     A.birth_date, \n",
    "                     concat(A.first_name, ' ', A.last_name) as Name, \n",
    "                     A.gender,\n",
    "                     B.salary,\n",
    "                     C.title\n",
    "              FROM employees AS A\n",
    "              JOIN salaries AS B\n",
    "              ON A.emp_no = B.emp_no\n",
    "              JOIN titles AS C\n",
    "              ON A.emp_no = C.emp_no\n",
    "             \"\"\" ).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+----------+---------+------+------+----------------+\n",
      "|emp_no|birth_date|first_name|last_name|gender|salary|           title|\n",
      "+------+----------+----------+---------+------+------+----------------+\n",
      "| 10206|1960-09-19|  Alassane|  Iwayama|     F| 40000|Technique Leader|\n",
      "| 10206|1960-09-19|  Alassane|  Iwayama|     F| 43519|Technique Leader|\n",
      "| 10206|1960-09-19|  Alassane|  Iwayama|     F| 46265|Technique Leader|\n",
      "| 10206|1960-09-19|  Alassane|  Iwayama|     F| 46865|Technique Leader|\n",
      "| 10206|1960-09-19|  Alassane|  Iwayama|     F| 47837|Technique Leader|\n",
      "+------+----------+----------+---------+------+------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Leguaje Api DF\n",
    "( employeesDF.join(salariesDF, employeesDF.emp_no == salariesDF.emp_no)\n",
    "             .join(titlesDF, salariesDF.emp_no == titlesDF.emp_no)\n",
    "             .select(employeesDF.emp_no, \"birth_date\", \"first_name\", \"last_name\", \"gender\", \"salary\", \"title\")\n",
    "             .show(5) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C.3 Diferencia entre Rank y dense_rank (operaciones de ventana)\n",
    "\n",
    "**Rank** realiza una clasificación o ranking dentro de su partición ordenada, en el caso de empates, se les asigna el mismo rango y se omiten los rangos siguientes. \n",
    "Ejemplo si tiene 3 elementos con rango 2, el siguiente listado seria el rango 5\n",
    "\n",
    "**Dense_rank** realiza una clasificación o ranking de dentro de su partición ordenada, pero los rangos se aplican de manera consecutiva, sin salartse ningun rango si hay rangos con varios elementos.\n",
    "\n",
    "Para el caso de valores nulos, dependen de la cláusula GROUP BY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------+------+----+\n",
      "|emp_no|             Name|salary|Rank|\n",
      "+------+-----------------+------+----+\n",
      "| 43624|   Tokuyasu Pesch|158220|   1|\n",
      "| 43624|   Tokuyasu Pesch|157821|   2|\n",
      "|254466|Honesty Mukaidono|156286|   3|\n",
      "| 47978|  Xiahua Whitcomb|155709|   4|\n",
      "|253939|    Sanjai Luders|155513|   5|\n",
      "+------+-----------------+------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ej mostramos los 5 empleados con más salario con rank\n",
    "spark.sql( \"\"\"SELECT A.emp_no, concat(A.first_name, ' ', A.last_name) as Name, B. salary,\n",
    "                     rank() over (ORDER BY B.salary DESC) AS Rank\n",
    "              FROM employees AS A\n",
    "              JOIN salaries AS B\n",
    "              ON A.emp_no = B.emp_no \"\"\" ).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------+------+----------+\n",
      "|emp_no|             Name|salary|Dense_Rank|\n",
      "+------+-----------------+------+----------+\n",
      "| 43624|   Tokuyasu Pesch|158220|         1|\n",
      "| 43624|   Tokuyasu Pesch|157821|         2|\n",
      "|254466|Honesty Mukaidono|156286|         3|\n",
      "| 47978|  Xiahua Whitcomb|155709|         4|\n",
      "|253939|    Sanjai Luders|155513|         5|\n",
      "+------+-----------------+------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ej mostramos los 5 empleados con más salario con dense_rank\n",
    "spark.sql( \"\"\"SELECT A.emp_no, concat(A.first_name, ' ', A.last_name) as Name, B. salary,\n",
    "                     dense_rank() over (ORDER BY B.salary DESC) AS Dense_Rank\n",
    "              FROM employees AS A\n",
    "              JOIN salaries AS B\n",
    "              ON A.emp_no = B.emp_no \"\"\" ).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
