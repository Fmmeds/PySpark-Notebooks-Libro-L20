{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capitulos 1 Introduction to Apache Spark's y 2: Download Apache Spark and Getting Started \n",
    "\n",
    "Iremos leyendo y realizando los ejemplos del capitulo 1 y 2 del libro, complementandolo con unos actividades sobre los mismos ejemplos. \n",
    "\n",
    "## Spark Session\n",
    "\n",
    "La aplicación de Spark se controla a través de un controlador llamado SparkSession. La instancia SparkSession es la forma en que se ejecuta Spark y el código definido por el usuario. \n",
    "\n",
    "##### Siempre debemos iniciar una instancia SparkSession al principio. \n",
    "\n",
    "Creamos nuestra SparkSession en una variable spark, dandole como nombre Tema2, y verificamos la versión de spark que tiene:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0.1\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "import random\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Creamos SparkSession (IMPORTANTE cambiar el nombre si estamos en otros script)\n",
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .appName(\"LibroSpark_cap1y2\")\\\n",
    "    .getOrCreate()\n",
    "\n",
    "#Vemos versión de spark\n",
    "print(spark.sparkContext.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicios Capitulo 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Descargar el Quijote \n",
    "https://gist.github.com/jsdario/6d6c69398cb0c73111e49f1218960f79\n",
    "#### Aplicar no solo count (para obtener el número de líneas) y show sino probar distintas sobrecargas del método show (con/sin truncate, indicando/sin indicar num de filas, etc) así como también los métodos, head, take, first (diferencias entre estos 3?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el archivo el_quijote\n",
    "Quijote = spark.read.text(\"./Datasets/el_quijote.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2186"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# El metodo count() cuenta el número de lineas (2186)\n",
    "Quijote.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(value='DON QUIJOTE DE LA MANCHA')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# El metodo first() devuelve solo la primera fila \n",
    "Quijote.first()\n",
    "\n",
    "# Fijemonos que las muestra en tipo en una lista de tipo Row [Row(value='')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               value|\n",
      "+--------------------+\n",
      "|DON QUIJOTE DE LA...|\n",
      "|Miguel de Cervant...|\n",
      "|                    |\n",
      "|       PRIMERA PARTE|\n",
      "|CAPÍTULO 1: Que ...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# El metodo show() devuelve el contenido del archivo por filas, en este caso 5, si no se indica numero, lo mostrará al completo.\n",
    "Quijote.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------------+\n",
      "|value                                                                                         |\n",
      "+----------------------------------------------------------------------------------------------+\n",
      "|DON QUIJOTE DE LA MANCHA                                                                      |\n",
      "|Miguel de Cervantes Saavedra                                                                  |\n",
      "|                                                                                              |\n",
      "|PRIMERA PARTE                                                                                 |\n",
      "|CAPÍTULO 1: Que trata de la condición y ejercicio del famoso hidalgo D. Quijote de la Mancha|\n",
      "+----------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Si nos fijamos, no muestra las filas al completo, añadiendo ... \n",
    "# Añadiendo al metodo show(truncate=False) Mostramos al completo las filas, por defecto este parámetro Truncate y es True\n",
    "# Se puede poner directamente False y entenderá que es truncate=False\n",
    "Quijote.show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(value='DON QUIJOTE DE LA MANCHA'),\n",
       " Row(value='Miguel de Cervantes Saavedra'),\n",
       " Row(value=''),\n",
       " Row(value='PRIMERA PARTE'),\n",
       " Row(value='CAPÍTULO 1: Que trata de la condición y ejercicio del famoso hidalgo D. Quijote de la Mancha')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# El metodo head() devuelve las primeras n filas, en este caso 5\n",
    "Quijote.head(5)\n",
    "\n",
    "# Fijemonos que las devuelve en tipo en una lista de tipo Row [Row(value='')] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(value='DON QUIJOTE DE LA MANCHA'),\n",
       " Row(value='Miguel de Cervantes Saavedra'),\n",
       " Row(value=''),\n",
       " Row(value='PRIMERA PARTE'),\n",
       " Row(value='CAPÍTULO 1: Que trata de la condición y ejercicio del famoso hidalgo D. Quijote de la Mancha')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# El metodo take() devuelve las primeras n filas, en este caso 5. \n",
    "# head() y take () son metodos similares\n",
    "Quijote.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A modo de conclusiones, las diferencias entre head, take y first son:\n",
    "- First solo devuelve la primera liena del archivo\n",
    "- Take y head devuelven las n primeras filas que le indiques en formato Row, siendo los dos metodos iguales\n",
    "- Show muestra el archivo por filas, pudiendo indicarle el numero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Del ejercicio del M&M aplicar:\n",
    "#### B1 Hacer ejemplo del libro\n",
    "#### B2 Otras operaciones de agregación como el Max con otro tipo de ordenamiento (descendiente).\n",
    "#### B3 Hacer un ejercicio como el “where” de CA que aparece en el libro pero indicando más opciones de estados (p.e. NV, TX, CA, CO).\n",
    "#### B4 Hacer un ejercicio donde se calculen en una misma operación el Max, Min, Avg, Count. Revisar el API (documentación) donde encontrarán este ejemplo:\n",
    "ds.agg(max($\"age\"), avg($\"salary\"))\n",
    "ds.groupBy().agg(max($\"age\"), avg($\"salary\"))\n",
    "NOTA: $ es un alias de col()\n",
    "iv.\tHacer también ejercicios en SQL creando tmpView\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B1 Hacer ejemplo del libro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importaciones necesarias\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows = 99999\n",
      "+-----+------+-----+\n",
      "|State| Color|Count|\n",
      "+-----+------+-----+\n",
      "|   TX|   Red|   20|\n",
      "|   NV|  Blue|   66|\n",
      "|   CO|  Blue|   79|\n",
      "|   OR|  Blue|   71|\n",
      "|   WA|Yellow|   93|\n",
      "+-----+------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- State: string (nullable = true)\n",
      " |-- Color: string (nullable = true)\n",
      " |-- Count: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cargamos DataFrame de M&M\n",
    "mnm_df = spark.read.option(\"header\", \"true\") \\\n",
    "          .option(\"inferSchema\", \"true\") \\\n",
    "          .csv(\"./Datasets/mnm_dataset.csv\")\n",
    "\n",
    "# Mostramos con un print el numero de lineas\n",
    "print(\"Total Rows = %d\" % (mnm_df.count()))\n",
    "\n",
    "# Inspeccionamos (show en modo tabla, take las coge como filas)\n",
    "mnm_df.show(5)\n",
    "# Vemos el schema del DF\n",
    "mnm_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Conteo agregado de todos los colores y gruposPor estado y color en orden descentende.\n",
    " \n",
    " Hemos creado un nuevo DF a través de una consulta que selecciona las columnas \"State\", \"Color\" y \"Count\" agregadas por \"State\" y \"Color\" ordenando por el total de la columna \"Count\" en orden descendente de mayor a menor.\n",
    " \n",
    "Count hace referencia al numero de veces que aparece un color estado, por lo que podremos ver los colores por estado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows = 60\n",
      "+-----+------+------+\n",
      "|State| Color| Total|\n",
      "+-----+------+------+\n",
      "|   CA|Yellow|100956|\n",
      "|   WA| Green| 96486|\n",
      "|   CA| Brown| 95762|\n",
      "|   TX| Green| 95753|\n",
      "|   TX|   Red| 95404|\n",
      "+-----+------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# B1 Total de colores agrupados por estado y color en orden descentende.\n",
    "count_mnm_df = (mnm_df.select(\"State\", \"Color\", \"Count\")\n",
    "                      .groupBy(\"State\", \"Color\")\n",
    "                      .agg(sum(\"Count\").alias(\"Total\"))\n",
    "                      .orderBy(\"Total\", ascending=False))\n",
    "\n",
    "# Mostramos con un print el numero de lineas\n",
    "print(\"Total Rows = %d\" % (count_mnm_df.count()))\n",
    "\n",
    "count_mnm_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------+\n",
      "|State|Color |Total |\n",
      "+-----+------+------+\n",
      "|CA   |Yellow|100956|\n",
      "|WA   |Green |96486 |\n",
      "|CA   |Brown |95762 |\n",
      "|TX   |Green |95753 |\n",
      "|TX   |Red   |95404 |\n",
      "|CO   |Yellow|95038 |\n",
      "|NM   |Red   |94699 |\n",
      "|OR   |Orange|94514 |\n",
      "|WY   |Green |94339 |\n",
      "|NV   |Orange|93929 |\n",
      "|TX   |Yellow|93819 |\n",
      "|CO   |Green |93724 |\n",
      "|CO   |Brown |93692 |\n",
      "|CA   |Green |93505 |\n",
      "|NM   |Brown |93447 |\n",
      "|CO   |Blue  |93412 |\n",
      "|WA   |Red   |93332 |\n",
      "|WA   |Brown |93082 |\n",
      "|WA   |Yellow|92920 |\n",
      "|NM   |Yellow|92747 |\n",
      "|NV   |Brown |92478 |\n",
      "|TX   |Orange|92315 |\n",
      "|AZ   |Brown |92287 |\n",
      "|AZ   |Green |91882 |\n",
      "|WY   |Red   |91768 |\n",
      "|AZ   |Orange|91684 |\n",
      "|CA   |Red   |91527 |\n",
      "|WA   |Orange|91521 |\n",
      "|NV   |Yellow|91390 |\n",
      "|UT   |Orange|91341 |\n",
      "|NV   |Green |91331 |\n",
      "|NM   |Orange|91251 |\n",
      "|NM   |Green |91160 |\n",
      "|WY   |Blue  |91002 |\n",
      "|UT   |Red   |90995 |\n",
      "|CO   |Orange|90971 |\n",
      "|AZ   |Yellow|90946 |\n",
      "|TX   |Brown |90736 |\n",
      "|OR   |Blue  |90526 |\n",
      "|CA   |Orange|90311 |\n",
      "|OR   |Red   |90286 |\n",
      "|NM   |Blue  |90150 |\n",
      "|AZ   |Red   |90042 |\n",
      "|NV   |Blue  |90003 |\n",
      "|UT   |Blue  |89977 |\n",
      "|AZ   |Blue  |89971 |\n",
      "|WA   |Blue  |89886 |\n",
      "|OR   |Green |89578 |\n",
      "|CO   |Red   |89465 |\n",
      "|NV   |Red   |89346 |\n",
      "|UT   |Yellow|89264 |\n",
      "|OR   |Brown |89136 |\n",
      "|CA   |Blue  |89123 |\n",
      "|UT   |Brown |88973 |\n",
      "|TX   |Blue  |88466 |\n",
      "|UT   |Green |88392 |\n",
      "|OR   |Yellow|88129 |\n",
      "|WY   |Orange|87956 |\n",
      "|WY   |Yellow|87800 |\n",
      "|WY   |Brown |86110 |\n",
      "+-----+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Mostramos todas las lineas \n",
    "count_mnm_df.show(60, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtramos el numero de colores por california (CA) en orden de mayor a menor.\n",
    " \n",
    "Hemos creado un nuevo DF a través de una consulta que filtra los colores seleccionando todas las columnas con la condicion where de que sean del State de california, agrupadas por State y Color y ordenadas de mayor a menor por el total de colores.\n",
    "\n",
    "Resumiendo vemos los colores y el total en el estado de california."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows = 6\n",
      "+-----+------+------+\n",
      "|State|Color |Total |\n",
      "+-----+------+------+\n",
      "|CA   |Yellow|100956|\n",
      "|CA   |Brown |95762 |\n",
      "|CA   |Green |93505 |\n",
      "|CA   |Red   |91527 |\n",
      "|CA   |Orange|90311 |\n",
      "|CA   |Blue  |89123 |\n",
      "+-----+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# B1.2 Filtramos por california (CA) Conteo agregado de todos los colores y gruposPor estado y color en orden descentende.\n",
    "ca_count_mnm_df = (mnm_df\n",
    "                .select(\"*\")\n",
    "                .where(mnm_df.State == 'CA')\n",
    "                .groupBy(\"State\", \"Color\")\n",
    "                .agg(sum(\"Count\").alias(\"Total\"))\n",
    "                .orderBy(\"Total\", ascending=False))\n",
    "\n",
    "# Mostramos con un print el numero de lineas\n",
    "print(\"Total Rows = %d\" % (ca_count_mnm_df.count()))\n",
    "\n",
    "# Mostramos el resultado para las 10 primeras filas, que en realidad son 6\n",
    "ca_count_mnm_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B2 Otras operaciones de agregación como el Max con otro tipo de ordenamiento (descendiente)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows = 60\n",
      "+-----+------+-------+\n",
      "|State| Color|Minimos|\n",
      "+-----+------+-------+\n",
      "|   CO|  Blue|     10|\n",
      "|   NM|Orange|     10|\n",
      "|   NM| Green|     10|\n",
      "|   UT|  Blue|     10|\n",
      "|   AZ|Orange|     10|\n",
      "+-----+------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "# B2 Agrupamos por State y color los valores minimos de colores (count) en cada estado en orden descendente \n",
    "min_mnm_df = (mnm_df.select(\"*\")\n",
    "                    .groupBy(\"State\", \"Color\")\n",
    "                    .agg(min(\"Count\").alias('Minimos'))\n",
    "                    .orderBy(\"Minimos\", ascending=False))\n",
    "\n",
    "# Mostramos con un print el numero de lineas\n",
    "print(\"Total Rows = %d\" % (min_mnm_df.count()))\n",
    "min_mnm_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B3 Hacer un ejercicio como el “where” de CA que aparece en el libro pero indicando más opciones de estados (p.e. NV, TX, CA, CO)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------+\n",
      "|State| Color| Total|\n",
      "+-----+------+------+\n",
      "|   CA|Yellow|100956|\n",
      "|   CA| Brown| 95762|\n",
      "|   TX| Green| 95753|\n",
      "|   TX|   Red| 95404|\n",
      "|   CO|Yellow| 95038|\n",
      "+-----+------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Los operadores booleanos AND, OR se escriben en spark como & y | Respectivamente (primer .where)\n",
    "# Se puede usar el operador in para varias condiciones englobandolo todo entre \"\" (segundo where)\n",
    "# en la condicion where() englobamos las columnas con el valor de la condicion y separando por el operador \n",
    "\n",
    "# B3 Filtramos por los estados (NV, TX, CA, CO) el Total de colores agrupados por estado y color en orden descentende.\n",
    "B3_mnm_df = (mnm_df.select(\"*\")\n",
    "                #.where( (mnm_df.State == 'CA') | (mnm_df.State == 'NV') | (mnm_df.State == 'CA') | (mnm_df.State == 'CO') )\n",
    "                .where(\"State in ('NV', 'TX', 'CA', 'CO')\")\n",
    "                .groupBy(\"State\", \"Color\")\n",
    "                .agg(sum(\"Count\").alias(\"Total\"))\n",
    "                .orderBy(\"Total\", ascending=False))\n",
    "B3_mnm_df.show(5)\n",
    "\n",
    "# Se puede sustituir la funcion where por filter obteniendo el mismo resultado. son funciones similares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B4 Hacer un ejercicio donde se calculen en una misma operación el Max, Min, Avg, Count. Revisar el API (documentación) donde encontrarán este ejemplo:\n",
    "\n",
    "ds.agg(max( $ \"age\"), avg( $ \"salary\"))\n",
    "\n",
    "ds.groupBy().agg(max( $ \"age\"), avg( $ \"salary\"))\n",
    "\n",
    "NOTA: $ es un alias de col()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+-------------+-------------+------------------+-----------+\n",
      "|State| Color|Maximos_count|Minimos_coutn|         AVG_count|Total_count|\n",
      "+-----+------+-------------+-------------+------------------+-----------+\n",
      "|   WY| Green|          100|           10|55.657227138643066|       1695|\n",
      "|   NV|   Red|          100|           10|  55.4944099378882|       1610|\n",
      "|   UT|  Blue|          100|           10|54.366767371601206|       1655|\n",
      "|   WA|Orange|          100|           10|55.199638118214715|       1658|\n",
      "|   NM| Green|          100|           10|  54.1973840665874|       1682|\n",
      "+-----+------+-------------+-------------+------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# B4 Select de todas las columnas agrupado por estado y color y calculando con agg minimos, maximos, media y numero de colores\n",
    "agg_mnm_df = (mnm_df.select(\"State\", \"Color\", \"Count\")\n",
    "              .groupBy(\"State\", \"Color\")\n",
    "              .agg( max(\"Count\").alias(\"Maximos_count\"), \n",
    "                    min(\"Count\").alias(\"Minimos_coutn\"),\n",
    "                    avg(\"Count\").alias(\"AVG_count\"), \n",
    "                    count(\"Count\").alias(\"Total_count\") )\n",
    "\n",
    ")\n",
    "\n",
    "agg_mnm_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B5 Hacer también ejercicios en SQL creando tmpView"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+-------------+-------------+------------------+-----------+\n",
      "|State| Color|Maximos_count|Minimos_coutn|         AVG_count|Total_count|\n",
      "+-----+------+-------------+-------------+------------------+-----------+\n",
      "|   WY| Green|          100|           10|55.657227138643066|       1695|\n",
      "|   NV|   Red|          100|           10|  55.4944099378882|       1610|\n",
      "|   UT|  Blue|          100|           10|54.366767371601206|       1655|\n",
      "|   WA|Orange|          100|           10|55.199638118214715|       1658|\n",
      "|   NM| Green|          100|           10|  54.1973840665874|       1682|\n",
      "+-----+------+-------------+-------------+------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creamos vista temporal del DF del ejercicio anterior (agg_mnm_df)\n",
    "agg_mnm_df.createOrReplaceTempView(\"agg_view\")\n",
    "\n",
    "# Así podremos hacer consultas puras en sql lanzando el sqlContext, como por ejemplo:\n",
    "results = spark.sql(\"SELECT * FROM agg_view LIMIT 5\")\n",
    "results.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, repetiremos todas las consultas agregadas realizadas anteriormente pero en formato SQL puro. Crearemos una vista temporal con el DF original y iremos haciendo las querys en SQL\n",
    "\n",
    "El resultado y el procesamiento por parte de Spark será igual indistintamente entre el trabajo con Dataframes y SQL puro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos vista temporal del DF mnm_df\n",
    "mnm_df.createOrReplaceTempView(\"mnm_df_view\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------+\n",
      "|State| Color| Total|\n",
      "+-----+------+------+\n",
      "|   CA|Yellow|100956|\n",
      "|   WA| Green| 96486|\n",
      "|   CA| Brown| 95762|\n",
      "|   TX| Green| 95753|\n",
      "|   TX|   Red| 95404|\n",
      "+-----+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# B1 Total de colores agrupados por estado y color en orden descentende. (SQLpuro)\n",
    "results_total_color = spark.sql(\"SELECT State, Color, sum(Count) AS Total \\\n",
    "                                 FROM mnm_df_view \\\n",
    "                                 GROUP BY State, Color \\\n",
    "                                 ORDER BY Total DESC  \\\n",
    "                                 LIMIT 5\") \\\n",
    "                           .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------+\n",
      "|State| Color| Total|\n",
      "+-----+------+------+\n",
      "|   CA|Yellow|100956|\n",
      "|   CA| Brown| 95762|\n",
      "|   CA| Green| 93505|\n",
      "|   CA|   Red| 91527|\n",
      "|   CA|Orange| 90311|\n",
      "+-----+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# B1.2 Filtramos por california (CA) Conteo agregado de todos los colores y gruposPor estado y color en orden descentende\n",
    "# (SQL puro).\n",
    "\n",
    "results_total_color_ca = spark.sql(\"SELECT State, Color, sum(Count) AS Total \\\n",
    "                                 FROM mnm_df_view \\\n",
    "                                 WHERE State = 'CA' \\\n",
    "                                 GROUP BY State, Color \\\n",
    "                                 ORDER BY Total DESC  \\\n",
    "                                 LIMIT 5\") \\\n",
    "                              .show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+-------+\n",
      "|State| Color|Minimos|\n",
      "+-----+------+-------+\n",
      "|   WY| Green|     10|\n",
      "|   NV|   Red|     10|\n",
      "|   UT|  Blue|     10|\n",
      "|   WA|Orange|     10|\n",
      "|   NM| Green|     10|\n",
      "+-----+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# B2 Agrupamos por State y color los valores minimos de colores (count) en cada estado en orden descendente \n",
    "# (SQL puro).\n",
    "results_min_color =  spark.sql(\"SELECT State, Color, min(Count) AS Minimos \\\n",
    "                                 FROM mnm_df_view \\\n",
    "                                 GROUP BY State, Color \\\n",
    "                                 ORDER BY Minimos DESC  \\\n",
    "                                 LIMIT 5\") \\\n",
    "                          .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------+\n",
      "|State| Color| Total|\n",
      "+-----+------+------+\n",
      "|   CA|Yellow|100956|\n",
      "|   CA| Brown| 95762|\n",
      "|   TX| Green| 95753|\n",
      "|   TX|   Red| 95404|\n",
      "|   CO|Yellow| 95038|\n",
      "+-----+------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# B3 Filtramos por los estados (NV, TX, CA, CO) el Total de colores agrupados por estado y color en orden descentende.\n",
    "# SQL puro\n",
    "results_B3 = spark.sql(\"SELECT State, Color, sum(Count) AS Total \\\n",
    "                        FROM mnm_df_view \\\n",
    "                        WHERE State IN ('NV', 'TX', 'CA', 'CO')\\\n",
    "                        GROUP BY State, Color \\\n",
    "                        ORDER BY Total DESC\") \\\n",
    "                  .show(5)\n",
    "\n",
    "# Podemos mostrar 5 columnas con show() o con LIMIT, pudiendo combinar los dos lenguajes (DF y SQL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+-------+-------+------------------+------+\n",
      "|State| Color|Minimos|Maximos|               AVG| Total|\n",
      "+-----+------+-------+-------+------------------+------+\n",
      "|   CA|Yellow|     10|    100|  55.8693967902601|100956|\n",
      "|   CA| Brown|     10|    100|55.740395809080326| 95762|\n",
      "|   TX| Green|     10|    100| 55.12550374208405| 95753|\n",
      "|   TX|   Red|     10|    100|55.306666666666665| 95404|\n",
      "|   CO|Yellow|     10|    100| 55.22254503195816| 95038|\n",
      "+-----+------+-------+-------+------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# B4 Select de todas las columnas agrupado por estado y color y calculando con agg minimos, maximos, media y numero de colores\n",
    "# SQL puro\n",
    "results_agg_B4 = spark.sql(\"SELECT State, Color, min(Count) AS Minimos, max(Count) AS Maximos, avg(Count) AS AVG, sum(Count) AS Total\\\n",
    "                                 FROM mnm_df_view \\\n",
    "                                 WHERE State IN ('NV', 'TX', 'CA', 'CO')\\\n",
    "                                 GROUP BY State, Color \\\n",
    "                                 ORDER BY Total DESC\") \\\n",
    "                      .show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
